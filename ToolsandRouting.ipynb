{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools and Rounting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM should decide which function to use and what the inputs to that function will be and calling the function with those inputs.\n",
    " Tools combine both of these ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can basically convert a function into a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our own tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool -  structured interaction with the external services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query:str)->str: #takes a string and indicates that the function is expected to return a string\n",
    "    \"\"\"Search for the wether online\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search', description='Search for the wether online', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x08F24F10>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve upon this by defining a more explicit structure by the input schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class SearchInput(BaseModel):\n",
    "    query:str = Field(description=\"thing to search for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema=SearchInput)\n",
    "def search(query:str)->str: #takes a string and indicates that the function is expected to return a string\n",
    "    \"\"\"Search for the wether online\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42f'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"dl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are creating a tool that will give the temperature given a latitude and the longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenMeteo(BaseModel):\n",
    "    latitude : float = Field(description=\"latitude of the location\")\n",
    "    longitude: float = Field(description=\"longitude of the location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema=OpenMeteo)\n",
    "def get_current_temperature(latitude:float,longitude :float)->dict:\n",
    "    \"\"\"Get the current temperature of the given coordinates\"\"\"\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "    params = {\n",
    "        'latitude':latitude,\n",
    "        'longitude':longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    #Make the resuest\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code==200: #status code if the resquest was successful\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API request failes with the status code :{response.status_code}\")\n",
    "    \n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get the current temperature of the given coordinates'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': {'description': 'latitude of the location',\n",
       "  'title': 'Latitude',\n",
       "  'type': 'number'},\n",
       " 'longitude': {'description': 'longitude of the location',\n",
       "  'title': 'Longitude',\n",
       "  'type': 'number'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can covert this tool to the openai function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': 'Get the current temperature of the given coordinates',\n",
       " 'parameters': {'properties': {'latitude': {'description': 'latitude of the location',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'longitude of the location',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 28.75,\n",
       " 'longitude': 77.125,\n",
       " 'generationtime_ms': 0.0133514404296875,\n",
       " 'utc_offset_seconds': 0,\n",
       " 'timezone': 'GMT',\n",
       " 'timezone_abbreviation': 'GMT',\n",
       " 'elevation': 224.0,\n",
       " 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C'},\n",
       " 'hourly': {'time': ['2025-01-16T00:00',\n",
       "   '2025-01-16T01:00',\n",
       "   '2025-01-16T02:00',\n",
       "   '2025-01-16T03:00',\n",
       "   '2025-01-16T04:00',\n",
       "   '2025-01-16T05:00',\n",
       "   '2025-01-16T06:00',\n",
       "   '2025-01-16T07:00',\n",
       "   '2025-01-16T08:00',\n",
       "   '2025-01-16T09:00',\n",
       "   '2025-01-16T10:00',\n",
       "   '2025-01-16T11:00',\n",
       "   '2025-01-16T12:00',\n",
       "   '2025-01-16T13:00',\n",
       "   '2025-01-16T14:00',\n",
       "   '2025-01-16T15:00',\n",
       "   '2025-01-16T16:00',\n",
       "   '2025-01-16T17:00',\n",
       "   '2025-01-16T18:00',\n",
       "   '2025-01-16T19:00',\n",
       "   '2025-01-16T20:00',\n",
       "   '2025-01-16T21:00',\n",
       "   '2025-01-16T22:00',\n",
       "   '2025-01-16T23:00'],\n",
       "  'temperature_2m': [11.6,\n",
       "   11.7,\n",
       "   11.7,\n",
       "   12.3,\n",
       "   13.7,\n",
       "   15.3,\n",
       "   15.3,\n",
       "   16.6,\n",
       "   17.2,\n",
       "   17.6,\n",
       "   17.3,\n",
       "   16.8,\n",
       "   16.2,\n",
       "   15.1,\n",
       "   14.2,\n",
       "   13.4,\n",
       "   12.7,\n",
       "   12.1,\n",
       "   11.6,\n",
       "   11.2,\n",
       "   10.8,\n",
       "   10.4,\n",
       "   9.9,\n",
       "   9.6]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature({\"latitude\":28.737651005980887,\"longitude\" : 77.12872502495725})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second tool we are going to make is a wikipedia tool which is going to search things in wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "@tool\n",
    "def search_wikipedia(query:str)->str:\n",
    "    \"\"\"Run wikipedia search and get the page summaries\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_wikipedia'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Run wikipedia search and get the page summaries'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': 'Run wikipedia search and get the page summaries',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: Tyagi\\nSummary: Tyagi, originally called Taga, is a cultivator caste who claim Brahmin status. The landholding community is confined to Western Uttar Pradesh, Haryana, Delhi and Rajasthan. They are often considered the highest of the agricultural castes. During the British Raj, they changed their name from Taga to Tyagi, and began claiming Brahmin status. As of a 1990 report by the Backward Classes Commission, Government of Haryana, they were mostly engaged in farming. The Government of Haryana granted reservation to Tyagis along with five other castes in 2016. However, the Punjab and Haryana High Court shortly put a stay on the government's order.\\n\\n\\n\\nPage: Sachin Tyagi\\nSummary: Sachin Tyagi is an Indian Hindi television actor and singer, best known for playing Manish Goenka in the TV soap Yeh Rishta Kya Kehlata Hai starting from 2016 . He is married to actress Rakshanda Khan.\\n\\nPage: Sucharita Tyagi\\nSummary: Sucharita Tyagi is an Indian film critic and former radio jockey. Born and brought up in New Delhi, India, she moved to Mumbai, transitioned into web content in 2015, and records weekly review videos for Film Companion.\\n\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia({\"query\":\"tyagi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routing \n",
    "Deciding the Language model which path to take and also the input to that path.\n",
    "Basically if we have 2 functions then which function the language model should choose and the inputs to that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lesson3, we show an example of function calling deciding between 2 candidate functions.\n",
    "Given our tools above we can format these as openai functions and show this same behavouir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10124\\2191828343.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(temperature = 0).bind(functions = functions)\n"
     ]
    }
   ],
   "source": [
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [ search_wikipedia, get_current_temperature]\n",
    "]\n",
    "model = ChatOpenAI(temperature = 0).bind(functions = functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":28.7041,\"longitude\":77.1025}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 99, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-e6922cff-4fef-4870-abc5-643bfb1d56a7-0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the weather like in DL now ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 95, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-05e86c28-64c0-473c-8872-0af6fabf7e2f-0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"WHat is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are helpful but sassy assistant\"),\n",
    "        (\"user\",\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='get_current_temperature', tool_input={'latitude': 28.7041, 'longitude': 77.1025}, log=\"\\nInvoking: `get_current_temperature` with `{'latitude': 28.7041, 'longitude': 77.1025}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":28.7041,\"longitude\":77.1025}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 107, 'total_tokens': 133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-8dca5d27-30c3-45ef-bab7-1ad046762cfe-0')])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Whats the weather like in delhi right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "functionenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
